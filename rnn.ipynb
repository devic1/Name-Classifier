{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqQtImBOSRvz",
        "outputId": "2a4a8c21-5155-4eea-f1aa-a4e0d9ab5bee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-11 08:56:20--  https://github.com/devic1/RNN-/raw/main/data.zip\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/devic1/RNN-/main/data.zip [following]\n",
            "--2023-02-11 08:56:20--  https://raw.githubusercontent.com/devic1/RNN-/main/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23197 (23K) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]  22.65K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-02-11 08:56:21 (102 MB/s) - ‘data.zip’ saved [23197/23197]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/devic1/RNN-/raw/main/data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgN3rf8vSnQk",
        "outputId": "2d334e4d-b0ee-414a-f7d4-4f192cc461a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/boys.txt           \n",
            "  inflating: data/girls.txt          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import os\n",
        "import unicodedata"
      ],
      "metadata": {
        "id": "qu31ekedUWD1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhI-0a6uhULN",
        "outputId": "9d7eb22e-2774-4e12-d207-6d3b52518ed9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lett = set()\n",
        "g = \" .,;'\"\n",
        "for i in g:\n",
        "  lett.add(i)\n",
        "lett"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHzKmhW5Z7Ha",
        "outputId": "8296af1b-b7cf-4f95-c003-16b2c5b6854e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ', \"'\", ',', '.', ';'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat = {}\n",
        "for i in os.listdir(\"data\"):\n",
        "  with open(os.path.join(\"data\",i),\"r\") as f:\n",
        "    nd = f.read().split(\"\\n\")\n",
        "    for j in nd:\n",
        "      for k in j:\n",
        "        lett.add(k)\n",
        "    cat[i[:-4]] = nd\n",
        "n_cat = len(cat)"
      ],
      "metadata": {
        "id": "ESqzUPceVWu9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ltoi = {j:i for i,j in enumerate(sorted(lett))}\n",
        "ln_l = len(ltoi)\n",
        "print(ltoi)\n",
        "ln_l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IINROYlaO7D",
        "outputId": "632a4c5e-f18e-46c2-ba09-5ac85fead07e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'\\t': 0, ' ': 1, \"'\": 2, ',': 3, '.': 4, '0': 5, ';': 6, 'ஃ': 7, 'அ': 8, 'ஆ': 9, 'இ': 10, 'உ': 11, 'ஊ': 12, 'எ': 13, 'ஏ': 14, 'ஐ': 15, 'ஒ': 16, 'ஓ': 17, 'க': 18, 'ங': 19, 'ச': 20, 'ஜ': 21, 'ஞ': 22, 'ட': 23, 'ண': 24, 'த': 25, 'ந': 26, 'ன': 27, 'ப': 28, 'ம': 29, 'ய': 30, 'ர': 31, 'ற': 32, 'ல': 33, 'ள': 34, 'ழ': 35, 'வ': 36, 'ஷ': 37, 'ஸ': 38, 'ஹ': 39, 'ா': 40, 'ி': 41, 'ீ': 42, 'ு': 43, 'ூ': 44, 'ெ': 45, 'ே': 46, 'ை': 47, 'ொ': 48, 'ோ': 49, 'ௌ': 50, '்': 51}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cat['boys'][:5])\n",
        "n_cat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gFa0Q3JVw_S",
        "outputId": "8d980190-6bc8-4b00-9a88-8087721c9df6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['அகண்டலன்', 'அகத்தியன்', 'அகரன்', 'அகரமுதல்வன்', 'அகற்கண்ணன்']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def enc(letter):\n",
        "  tempt = torch.tensor([])\n",
        "  for idx,ele in enumerate(letter):\n",
        "    c = torch.nn.functional.one_hot(torch.tensor(ltoi[ele]),num_classes=ln_l)\n",
        "    tempt = torch.cat((tempt,c.unsqueeze(0)),dim=0)\n",
        "  return tempt.view(-1,1,ln_l)"
      ],
      "metadata": {
        "id": "O9g_W56NZavi"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = enc(\"அகண்டலன்\")\n",
        "f[0].shape"
      ],
      "metadata": {
        "id": "wM4NLkqDdTjK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29554081-8e64-47b1-e3c7-1232ed66a6ee"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 52])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "catn = list(cat.keys())\n",
        "def getdata(train=True):\n",
        "  ranc = torch.randint(0,2,(1,))\n",
        "  catname = catn[ranc]\n",
        "  ln = len(cat[catname])\n",
        "  split = int(0.9*ln)\n",
        "  if train:\n",
        "    ranw = torch.randint(0,split,(1,))\n",
        "  else:\n",
        "    ranw = torch.randint(split,ln,(1,))\n",
        "  wtt = cat[catname][ranw]\n",
        "  if len(wtt) == 0:\n",
        "    return getdata()\n",
        "  return ranc,enc(wtt),catname,wtt"
      ],
      "metadata": {
        "id": "fRPqK2T3XQuG"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)\n",
        "        hidden = self.i2h(combined)\n",
        "        output = self.i2o(combined)\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "n_hidden = 128"
      ],
      "metadata": {
        "id": "Ff6559Jng2nq"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = RNN(ln_l, n_hidden, n_cat).to(device)"
      ],
      "metadata": {
        "id": "Y7i2yJgKhQvA"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(rnn.parameters(),lr=0.005)"
      ],
      "metadata": {
        "id": "bYA-STardFTm"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100000\n",
        "rnn.train()\n",
        "for i in range(epochs):\n",
        "  label,inp,name,word = getdata()\n",
        "  hidden = rnn.initHidden()\n",
        "  inp,hidden,label = inp.to(device),hidden.to(device),label.to(device)\n",
        "  for j in range(len(word)):\n",
        "    output,hidden = rnn(inp[j],hidden)\n",
        "  loss = loss_fn(output,label)\n",
        "  optimizer.zero_grad()  \n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if i % (epochs/10) == 0:\n",
        "    print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH2qp9R-Ws48",
        "outputId": "92f73db1-4d07-445f-e607-505bcc971a2f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(2.2324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.3088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.2646, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.1219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0314, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0.0220, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn.eval()\n",
        "epoch = 1000\n",
        "num_miss = 0\n",
        "for j in range(epoch):\n",
        "  label,inp,name,word = getdata(train=False)\n",
        "  hidden = rnn.initHidden()\n",
        "  inp,hidden,label = inp.to(device),hidden.to(device),label.to(device)\n",
        "  for k in range(len(word)):\n",
        "    output,hidden = rnn(inp[k],hidden)\n",
        "  h,res = output.topk(1)\n",
        "  if res != label:\n",
        "    num_miss += 1"
      ],
      "metadata": {
        "id": "fAc0_Qp8cSIt"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = 100-((num_miss/epoch)*100)\n",
        "print(f'The accuracy for the model is {accuracy}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ7ft1ZKleov",
        "outputId": "f34e356c-a3ac-457f-9573-661e80393e6b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy for the model is 81.7%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = \"விக்டர்\"\n",
        "#n = \"த்ரிஷா\"\n",
        "#n = input(\"Enter the name : \")\n",
        "inp = enc(n).to(device)\n",
        "for i in range(len(n)):\n",
        "  hid = rnn.initHidden().to(device)\n",
        "  ans,hid = rnn(inp[i],hid)\n",
        "_,result = ans.topk(1)\n",
        "print(f'The Name {n} is a {catn[result][:-1]} name.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIwLH6FPuvEG",
        "outputId": "b52db9d3-9087-4b1f-9275-5122ed0a04de"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Name விக்டர் is a boy name.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Happy Ending :)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz0Z8lHCtLTc",
        "outputId": "2722cc55-4b62-42b9-b871-ad928c3b9c40"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Happy Ending :)\n"
          ]
        }
      ]
    }
  ]
}